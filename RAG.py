# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cX-1b76jiRFRqnJp25Nk_EoaPixZcYJN
"""

!pip install -q langchain
!pip install -q torch
!pip install -q transformers
!pip install -q sentence-transformers
!pip install -q datasets
!pip install -q faiss-cpu
from langchain.document_loaders import HuggingFaceDatasetLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from transformers import AutoTokenizer, AutoModelForQuestionAnswering
from transformers import AutoTokenizer, pipeline
from langchain import HuggingFacePipeline
from langchain.chains import RetrievalQA
!pip install selenium
!pip install xmltodict
!pip install webdriver_manager
from selenium import webdriver
import os
import time
import xmltodict
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

#Config Web Scraping
class Browser:

    def __init__(self):

        self.service = Service()
        self.browser = webdriver.Chrome(service=self.service)
        self.timeout = 10
        self.wait = WebDriverWait(self.browser, self.timeout)

    def open_page(self, url:str):
        self.browser.get(url)

    def close_browser(self):
        self.browser.close()

    def add_input(self, by:By, value:str, text:str):
        field = self.browser.find_element(by=by, value=value)
        field.send_keys(text)
        time.sleep(1)

    def Keys_input(self, by:By, value:str, text:str):
           field = self.browser.find_element(by=by, value=value)
           field.send_keys(text)
           time.sleep(1)

    def click_button(self, by:By, value:str):
        button = self.browser.find_element(by=by, value=value)
        button.click()
        time.sleep(1)

    def scrape_res (self):
        self.click_button(by=By.XPATH, value='//*[@id="busquedaEmpleoBecasBean"]/section/div/div/div/button')
        self.wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id="busquedaEmpleoBecasBean"]/section[2]/div/div/div[3]/button')))
        self.click_button(by=By.XPATH, value='//*[@id="busquedaEmpleoBecasBean"]/section[2]/div/div/div[3]/button')
        os.rename(r"/Users/joanmiquel/Downloads/empleoResultados_Busqueda_Becas.xml", r"/Users/joanmiquel/Desktop/SocialHack/SocialHack/empleoResultados_Busqueda_Becas.xml")

#Run
if __name__ == '__main__':
    data_dict = {}
    browser = Browser()
    time.sleep(1)
    browser.open_page("https://administracion.gob.es/pagFront/empleoBecas/becasAyudasPremios/buscadorBecas.htm")
    browser.scrape_res()
    time.sleep(2)
    browser.close_browser()
    with open("empleoResultados_Busqueda_Becas.xml") as xml_file:
        data_dict = xmltodict.parse(xml_file.read())

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
import xmltodict
drive.mount('/content/drive')
# %cd /content/drive/MyDrive/Colab_Notebooks/prog_datasci_3

with open("empleoResultados_Busqueda_Becas.xml") as xml_file:
        data_dict = xmltodict.parse(xml_file.read())

data_dict = data_dict['BECAS']['BECA']

mylist = list()
nl = '\n'

for i in data_dict:
  text = str()
  for j,k in i.items():
    text += f'{j}:{k}.{nl}'
  mylist.append(text)

# Define the path to the pre-trained model you want to use
modelPath = "sentence-transformers/all-MiniLM-l6-v2"

# Create a dictionary with model configuration options, specifying to use the CPU for computations
model_kwargs = {'device':'cpu'}

# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False
encode_kwargs = {'normalize_embeddings': False}

# Initialize an instance of HuggingFaceEmbeddings with the specified parameters
embeddings = HuggingFaceEmbeddings(
    model_name=modelPath,     # Provide the pre-trained model's path
    model_kwargs=model_kwargs, # Pass the model configuration options
    encode_kwargs=encode_kwargs # Pass the encoding options
)

context = []
for i in mylist:
  context.append(embeddings.embed_query(i))

import numpy as np
query='Rehabilitar edificio'
query_result = embeddings.embed_query(query)

similarity = []
for i in context:
  similarity.append(np.dot(query_result,i)/np.linalg.norm(query_result)*np.linalg.norm(i))

results_index = [similarity.index(x) for x in similarity if x > np.quantile(similarity,0.99)]
for i in results_index:
  print(mylist[i])

#%% gpt rag

#!pip install openai
#!pip install tiktoken
#!pip install langchain
from langchain.chat_models import ChatOpenAI
import openai
import tiktoken

chat = ChatOpenAI(
    openai_api_key = '',
    model = 'gpt-3.5-turbo'
    )

from langchain.schema import SystemMessage, HumanMessage, AIMessage

message = [
    SystemMessage(content = ''),
    AIMessage(content = ''),
    HumanMessage(content = '')
    ]

#Initial context
response = chat(message)
response.content
message.append(response)

#prompt
prompt = HumanMessage(content = 'Tell me about dinosaurs')
message.append(prompt)

response = chat(message)
print(response.content)
